FROM rocm/pytorch:rocm6.4.4_ubuntu24.04_py3.12_pytorch_release_2.7.1
ENV DEBIAN_FRONTEND=noninteractive

ENV HSA_OVERRIDE_GFX_VERSION=11.0.0
ENV GPU_MAX_ALLOC_PERCENT=100
ENV GPU_MAX_HEAP_SIZE=100
ENV HSA_ENABLE_SDMA=0
ENV TORCH_ROCM_AOTRITON_ENABLE_EXPERIMENTAL=1
ENV MIOPEN_LOG_LEVEL=4
ENV PYTHONUNBUFFERED=1

RUN apt-get update && apt-get install -y git ffmpeg sox libsox-dev build-essential && rm -rf /var/lib/apt/lists/*

WORKDIR /app
RUN git clone https://github.com/QwenLM/Qwen3-TTS.git .

RUN pip install --no-cache-dir torchaudio --index-url https://download.pytorch.org/whl/rocm6.4

RUN echo 'from importlib.metadata import version' > /tmp/gen_constraints.py \
    && echo 'for pkg in ["torch", "torchaudio"]:' >> /tmp/gen_constraints.py \
    && echo '    v = version(pkg).split("+")[0]' >> /tmp/gen_constraints.py \
    && echo '    print(f"{pkg}=={v}")' >> /tmp/gen_constraints.py \
    && python /tmp/gen_constraints.py > /tmp/torch-constraints.txt

RUN pip install --no-cache-dir setuptools wheel soundfile gradio \
    && pip install --no-cache-dir -c /tmp/torch-constraints.txt -e .

RUN pip uninstall torchvision -y 2>/dev/null || true
RUN LOSS_UTILS=$(python -c "import transformers.loss; import os; print(os.path.join(os.path.dirname(transformers.loss.__file__), 'loss_utils.py'))") \
    && sed -i '/ForSegmentation/d' "$LOSS_UTILS" \
    && sed -i '/ObjectDetection/d' "$LOSS_UTILS" \
    && sed -i '/object_detection/d' "$LOSS_UTILS" \
    && sed -i '/GroundingDino/d' "$LOSS_UTILS" \
    && sed -i '/grounding_dino/d' "$LOSS_UTILS" \
    && sed -i '/Detr/d' "$LOSS_UTILS" \
    && sed -i '/detr/d' "$LOSS_UTILS" \
    && sed -i '/DFine/d' "$LOSS_UTILS" \
    && sed -i '/d_fine/d' "$LOSS_UTILS"

RUN sed -i '/model = AutoModel.from_pretrained/i \        kwargs["attn_implementation"] = "sdpa"' qwen_tts/inference/qwen3_tts_model.py
RUN sed -i 's/with gr.Blocks(theme=theme, css=css) as demo:/with gr.Blocks() as demo:/' qwen_tts/cli/demo.py

# ==========================================================
# ğŸ’¥ æç®€çº¯å‡€ç‰ˆï¼šæ”¾å¼ƒè®¡æ—¶å™¨ï¼Œç›´æ¥åœ¨ç±»å®šä¹‰çº§åˆ«é”æ­» CPU å±æ€§ï¼
# ==========================================================
RUN cat << 'EOF' > /app/run_demo.py
import sys
import torch
import torchaudio
import soundfile as sf
from qwen_tts.cli.demo import main
from qwen_tts.inference.qwen3_tts_model import Qwen3TTSModel

# è§„é¿ torchaudio ä¿å­˜å´©æºƒ
def patched_torchaudio_save(filepath, src, sample_rate, *args, **kwargs):
    sf.write(filepath, src.squeeze().cpu().numpy(), sample_rate)
torchaudio.save = patched_torchaudio_save

original_from_pretrained = Qwen3TTSModel.from_pretrained

@classmethod
def patched_from_pretrained(cls, *args, **kwargs):
    kwargs['dtype'] = torch.float16
    print(">> [AMD Hack] å¼ºåˆ¶è¦æ±‚ FP16 ç²¾åº¦...", flush=True)
    wrapper_model = original_from_pretrained(*args, **kwargs)
    
    try:
        target_tokenizer = wrapper_model.model.speech_tokenizer
        TokenizerClass = target_tokenizer.__class__
        
        # 1. æªå‡ºåº•å±‚çš„ BigVGAN ç‰©ç†å®ä½“å¹¶è½¬ç§»è‡³ CPU
        real_vocoder = target_tokenizer.model if hasattr(target_tokenizer, 'model') else target_tokenizer
        print(f">> [AMD Hack] æ­£åœ¨å°† {type(real_vocoder).__name__} å‘é…è‡³ 16 æ ¸ CPU...", flush=True)
        real_vocoder.to('cpu').float()
        
        # 2. ç»ˆæå¤§æ‹›ï¼šç›´æ¥é‡å†™è¯¥ç±»çš„ device å±æ€§ï¼
        # è¿™æ ·æ— è®ºå†…éƒ¨ä»£ç æ€ä¹ˆè°ƒç”¨ self.deviceï¼Œæ°¸è¿œåªä¼šè¿”å› cpuï¼Œå½»åº•ææ–­æ•°æ®å›æµ GPU çš„å¯èƒ½ï¼
        TokenizerClass.device = property(lambda self: torch.device('cpu'))
        
        # 3. åœ¨ç±»çº§åˆ«ï¼ˆClass Levelï¼‰æ‹¦æˆªè¾“å…¥æ•°æ®ï¼Œç¡®ä¿ç±»å‹ç»å¯¹å¹²å‡€
        if hasattr(TokenizerClass, 'decode'):
            orig_decode = TokenizerClass.decode
            def new_decode(self, *d_args, **d_kwargs):
                def _to_cpu(x):
                    if isinstance(x, torch.Tensor): return x.cpu()
                    if isinstance(x, tuple): return tuple(_to_cpu(i) for i in x)
                    if isinstance(x, list): return [_to_cpu(i) for i in x]
                    if isinstance(x, dict): return {k: _to_cpu(v) for k, v in x.items()}
                    return x
                return orig_decode(self, *_to_cpu(d_args), **_to_cpu(d_kwargs))
            TokenizerClass.decode = new_decode
            
        print(">> [AMD Hack] æ ¸å¿ƒæ‰‹æœ¯å®Œæˆï¼çº¯å‡€åˆ‡åˆ†æ¨¡å¼å·²å¯åŠ¨ï¼", flush=True)
    except Exception as e:
        print(f">> [AMD Hack] è­¦å‘Š: å¼‚æ„åˆ‡åˆ†å¤±è´¥: {e}", flush=True)
            
    return wrapper_model

Qwen3TTSModel.from_pretrained = patched_from_pretrained

if __name__ == "__main__":
    sys.argv[0] = "qwen-tts-demo"
    sys.exit(main())
EOF

CMD ["python3", "/app/run_demo.py", "Qwen/Qwen3-TTS-12Hz-1.7B-CustomVoice", "--ip", "0.0.0.0", "--port", "8100"]
